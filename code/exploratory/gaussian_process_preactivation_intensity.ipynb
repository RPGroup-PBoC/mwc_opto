{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling the Time-Dependent Pre-activation Signal Using Gaussian Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import bokeh.io \n",
    "import bokeh.plotting \n",
    "import pystan \n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I perform a cursory exploration of using Gaussian Process modeling to describe how the pre-activation intensity is dependent on time. The approach presented in this notebook is designed to be a section of a larger model that will consider all facets of the data as a single entity. Thus, this notebook serves as a proof-of-principle for pursuing this approach at a larger scale. \n",
    "\n",
    "In this notebook, I will very briefly summarize what a Gaussian process is and why it is applicable to this problem. I will then build a statistical model using the Stan probabilistic programming language to sample the parameter space for the GP hyperparameters. After defining the model,  I perform a series of checks to ensure the model works as advertised before applying it to the real-life data provided by Abrar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WTF is a Gaussian Process?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TL;DR - A Gaussian Process GP is a convenient way model the relationship between points without specifying a parametric relationship between them.**\n",
    "\n",
    "In science, we often make experimental measurements of set of variates $x$ and covariates $y$. In many cases, we can perform a regression to identify the statistical relationship between $x$ and $y$, and this often involves estimating parameter values, such as the slope $\\alpha$ and intercept $\\beta$ in a linear regression. In such a case, we can estimate the posterior probability distribution of the parameters $\\alpha, \\beta$ given experimental measurements via Bayes' theorem, which states \n",
    "\n",
    "$$\n",
    "P(\\alpha,\\beta,\\vert\\, x, y) = \\frac{P(y, x\\,\\vert\\,\\alpha, \\beta)P(\\alpha,\\beta)}{P(x, y)}. \\tag{1}\n",
    "$$\n",
    "\n",
    "Here $P(\\alpha,\\beta\\, \\vert\\, x, y)$ is the posterior distribution which defines a probability density over the parameters. The likelihood, $P(y, x\\,\\vert\\, \\alpha, \\beta)$, captures the probability density of observing the data ($y, x$) given the parameters $\\alpha$ and $\\beta$, and the prior distribution $P(\\alpha, \\beta)$ captures all prior knowledge we have of the values of these parameters *without* considering the data. The denominator $P(x, y)$ is the likelihood marginalized over the parameters $\\alpha$ and $\\beta$, and is not particularly relevant to this discussion. \n",
    "\n",
    "While this is nice, it is not always the case that we have a parametric expectation of how the variats and covariats are related. A perfect example of this is precisely the topic of this notebook -- the spooky time-dependent pre-activation signal. We have no real *a priori* reason to believe that it should be linear, other than it kinda-sorta looks like it might be. Rather than performing parameteric inference on these data, we can try to describe it in a non-parametric way.\n",
    "\n",
    "\n",
    "The formalism shown in Eq. 1 is true for any logical conjecture and is *not* restricted to computing probabilities over parameters. Rather, we could replace some of the terms in Eq. 1 to account for an unknown data-generating function $f$ as\n",
    "\n",
    "$$\n",
    "P(f\\,\\vert\\, x, y) = \\frac{P(x, y\\,\\vert\\, f)P(f)}{P(x, y)}. \\tag{2}\n",
    "$$\n",
    "\n",
    "It's a bit weird to think of probability densities over functions. We can instead think of $P(f\\,\\vert\\, x, y)$ as a probability density over the values of a functions at a given finite number of points $\\mathbf{X}$. Thus, with $N$ total observations (points), we can define a joint distribution over these values as $P(f(x_1), f(x_2), \\dots, f(x_N))$ where $x_1, x_2, \\dots, x_N \\in \\mathbf{X}$. For mathematical convenience (and courtesy of the central limit theorem), we can (and will) state that this joint distribution is a multi-variate Gaussian distribution with a mean function $m$ and a covariance function $k$. This defines a Gaussian Process (hereafter, GP).\n",
    "\n",
    "## WTF is a \"mean function\"?\n",
    "**TL;DR - Who cares? We can just set it to 0 (so long as are we are careful).**\n",
    "\n",
    "Gaussian distributions are defined by location and scale parameters $\\mu$, and $\\sigma$, respectively. As we are considering a Gaussian distribution over possible values of an arbitrary function $f$, we must define the location and scale parameters as *functions* of the variate $x$. Thus, we can state that a given function $f$ evalated over a set of finite points $\\mathbf{X}$ can be denoted as \n",
    "\n",
    "$$\n",
    "f(\\mathbf{X}) \\sim \\mathcal{GP}(m(\\mathbf{X}), k(\\mathbf{X})).\n",
    "$$\n",
    "\n",
    "If we have some prior knowledge of what this mean should be, we *could* prescribe this into our statistical model (Eq. 2). But, we don't have to. To remain completely non-parametric, we can just take the mean function evvaluated at a point to be 0, **so long as we center the measurements about 0**.  Since we wish to model the relationship between $x$ and $y$ about the mean of some unknown function, we can center and scale our data about 0 by \n",
    "\n",
    "$$ \n",
    "\\mathbf{X}_{s} = \\frac{\\mathbf{X} - \\bar{\\mathbf{X}}}{\\sigma_\\mathbf{X}}, \\tag{3}\n",
    "$$\n",
    "\n",
    "wehre $\\bar{\\mathbf{x}}$ is the arithmetic mean and $\\sigma_\\mathbf{X}$ is the variance. After we do our non-parametric inference, we can reverse this linear transformation to get back to the dimensions pertinent to our research question. \n",
    "\n",
    "## WTF is a \"covariance function\"?\n",
    "**TL;DR - Covariance function is a kernel which describes how points are correlated. Lot's of choices, but you can usually use a squared exponential kernel (we will).**\n",
    "\n",
    "A covariance function, or more simply termed a kernel, describes the different points are related to one another. In a multivariate world, we numerically identify how each pair of points are related to one another as a matrix. If we say that we have $N$ rows in our multivariate matrix $X$, then the covariance matrix is an $N\\times N$ matrix with entries of \n",
    "\n",
    "$$\n",
    "K_{i,j} = k(x_i, x_j). \\tag{4}\n",
    "$$\n",
    "Because we are considering a multi-dimensional Gaussian distribution,  the covariance matrix $K(\\mathbf{X}, \\mathbf{X'})$ has some mathematical requirements (must be positive-definite for the curious nerds), meaning that we are restricted in our choices. There are a bunch of different kernels $k$ that can be used., with the most commonly used one being the squared-exponential kernel\n",
    "\n",
    "$$\n",
    "k(x_1, x_2) = \\alpha^2 \\exp \\left(-\\frac{(x_1 - x_2)^2}{\\beta^2}\\right), \\tag{5}\n",
    "$$\n",
    "\n",
    "where $\\alpha$ and $\\beta$ are called **hyper-parameters** which we will have to infer later on. This is a very commonly used kernel and will be what we use here. \n",
    "\n",
    "## WTF is my prior knowledge of the possible function?\n",
    "**TL;DR - For a GP, it has to be a multivariate normal (a \"conjugate prior\") defined by your kernel.**\n",
    "\n",
    "Now that we've introduced a functional form for the kernel, we have some parameters that we need to care about. These hyperparameters, $\\alpha,  \\beta$ then inform our prior distribution over $f$  as  $P(f\\,vert\\, \\alpha, \\beta)$. Later on, we will put priors on the hyper-parameters themselves, creating a prior sandwich. \n",
    "\n",
    "For convvenience, we will say that the prior distribution over $f$ is a multivariate Gaussian distribution over a set of finite points where the variance is our covariance matrix $K(\\mathbf{X}, \\mathbf{X'})$ As the kernel describes how the points are related to one another, we can center our prior distribution again about 0, much as we did in defining the mean function, yielding \n",
    "\n",
    "$$\n",
    "P(f\\,\\vert\\, \\alpha, \\beta) = \\text{Gaussian}(0, K(\\mathbf{X}, \\mathbf{X'})\\,\\vert\\, \\alpha, \\beta). \\tag{6}\n",
    "$$\n",
    "\n",
    "An immense convenience of choosing a multivariate normal distribution for the prior is that it is the conjugate prior for a multivariate normal likelihood (what we have!). This means that the posterior distribution *itself* is a multivariate normal distribution, making things much (much) easier for us to code and draw samples from. However, we do include one more parameter $\\sigma$ which is a constant measurement error. As multiple measurements of the same variate can yield different vaulues, we can include this homoscedastic error into our kernel as \n",
    "\n",
    "$$\n",
    "P(f(x)\\,\\vert\\, x, y) \\sim \\mathcal{GP}(0, k(\\mathbf{X}, \\mathbf{X'} + \\delta_{\\mathbf{x}, \\mathbf{x'}}\\sigma)), \\tag{7}\n",
    "$$\n",
    "\n",
    "where $\\delta$ is a Kroneker delta function and is equal to unity only when the compared variates are identical. \n",
    "\n",
    "## Okay, what else?\n",
    "\n",
    "I'm going to omit some of the mathy grunge for now, but Gaussian matrices have some neat tricks up their sleeves with regards to getting the conditional distribution from the joint distribution. The result is that we can solve for the mean value of the mean function (and therefore, the most likely value) through products of covariance matrices. These require tough (and computationally intensive) matrix inversions. In the code that will come in this document, we can trick our computer into computing the inverted matrices by doing something called a Cholesky decomposition.\n",
    "\n",
    "I'm also leaving out some discussion of how we ultimately infer the values of the hyperparameters. This will be baked into the code to follow, but we can discuss this in depth at a later time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "Abrar sent me some processed data from two experiments where the preactivation signal was provided. We will load this data set and look only at the first experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"adf589ee-599a-46ac-b61d-4676b3d7b88e\" data-root-id=\"1002\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"dabe9b76-b988-4415-90af-6a5f9b319bf0\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1011\",\"type\":\"LinearAxis\"}],\"center\":[{\"id\":\"1015\",\"type\":\"Grid\"},{\"id\":\"1020\",\"type\":\"Grid\"}],\"left\":[{\"id\":\"1016\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"1038\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1041\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1027\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"1003\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"1007\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1005\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1009\",\"type\":\"LinearScale\"}},\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"time_min\"},\"y\":{\"field\":\"preact_intensity\"}},\"id\":\"1036\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"SaveTool\"},{\"attributes\":{\"callback\":null},\"id\":\"1005\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"LinearScale\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1048\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"1046\",\"type\":\"Selection\"},{\"attributes\":{\"ticker\":{\"id\":\"1012\",\"type\":\"BasicTicker\"}},\"id\":\"1015\",\"type\":\"Grid\"},{\"attributes\":{\"axis_label\":\"time [min]\",\"formatter\":{\"id\":\"1042\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1012\",\"type\":\"BasicTicker\"}},\"id\":\"1011\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1022\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"overlay\":{\"id\":\"1048\",\"type\":\"BoxAnnotation\"}},\"id\":\"1023\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1047\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1021\",\"type\":\"PanTool\"},{\"attributes\":{\"callback\":null,\"data\":{\"experiment_id\":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"index\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51],\"power_density_nW\":{\"__ndarray__\":\"WY/teUIJ/z9Zj+15Qgn/P3gWmScGI/M/eBaZJwYj8z+CuUFp1O/mP4K5QWnU7+Y/Ub/gNxtJ3D9Rv+A3G0ncP3OTjR2Uf8Y/a7xvWthw0T9rvG9a2HDRP3OTjR2Uf8Y/veAIya2+uz+94AjJrb67PwrwKLx9G7E/CvAovH0bsT+PpW1jg1ChP4+lbWODUKE/Iv1+TBSrnD8i/X5MFKucP1lR9tfL/bY/Ka8i0iG1lj/5vPpM1CoJQPm8+kzUKglApfGpPEQrCUCl8ak8RCsJQKXxqTxEKwlApfGpPEQrCUCl8ak8RCsJQKXxqTxEKwlAWY/teUIJ/z9Zj+15Qgn/P1mP7XlCCf8/grlBadTv5j+CuUFp1O/mP4K5QWnU7+Y/a7xvWthw0T9rvG9a2HDRP2u8b1rYcNE/veAIya2+uz+94AjJrb67P73gCMmtvrs/Ub/gNxtJ3D9Rv+A3G0ncP1G/4DcbSdw/eBaZJwYj8z94FpknBiPzP3gWmScGI/M/+bz6TNQqCUD5vPpM1CoJQFlR9tfL/bY/Ka8i0iG1lj8=\",\"dtype\":\"float64\",\"shape\":[52]},\"preact_intensity\":[466,444,483,494,514,520,701,899,644,804,686,636,743,955,963,953,946,1062,832,780,850,799,897,1286,1280,1436,1307,1275,1270,1303,1280,1215,1400,1357,1403,1334,1280,1368,1380,1462,1359,1459,1466,1550,1410,1305,1443,1600,1588,1482,1425,1492],\"saturation_intensity\":{\"__ndarray__\":\"AAAAAAAyokAAAAAAAOSRQAAAAAAAuIpAAAAAAABIiUAAAAAAAECFQAAAAAAAQIVAAAAAAADAh0AAAAAAABCJQAAAAAAAYHpAAAAAAACgfkAAAAAAAGB4QAAAAAAAQHpAAAAAAACQeUAAAAAAANB5QAAAAAAA4HVAAAAAAABAdkAAAAAAAGBkQAAAAAAAgFlAAAAAAACQUUAAAAAAAEBbQAAAAAAA4GhApHA9CtejS0AAAAAAAKCKQAAAAAAAFJBAAAAAAACMkUAAAAAAALCQQAAAAAAAmJBAAAAAAABwi0AAAAAAALiKQAAAAAAAAIpAAAAAAADoh0AAAAAAAOiHQAAAAAAAKIpAAAAAAABghUAAAAAAAJiDQAAAAAAA0IRAAAAAAAAgeUAAAAAAAIB5QAAAAAAAwHpAAAAAAADAdkAAAAAAAIBvQAAAAAAAIG5AAAAAAACgf0AAAAAAAOiAQAAAAAAA0INAAAAAAACQikAAAAAAAOCKQAAAAAAAqIlAAAAAAAB4j0AAAAAAAACPQAAAAAAAwGRAAAAAAAAARkA=\",\"dtype\":\"float64\",\"shape\":[52]},\"time_min\":{\"__ndarray__\":\"AAAAAAAAAAC49Shcj8IhQHBmZmZmZidA4VG4HoXrLED8KFyPwnUxQATXo3A9CjRAhsL1KFyPNkC49Shcj0I5QGRmZmZm5jtAZGZmZmbmO0CKFK5H4Xo+QHE9CtejcEBAvR6F61G4QkAF16NwPQpEQD8K16NwPUVAyfUoXI9CRkA8CtejcD1IQE7hehSuh0lAv/UoXI/CSkBkZmZmZuZLQJLC9ShcT01A02kDnTaQTkARrkfhehRQQBSuR+F61FBAzMzMzMyMUUDVo3A9ChdSQLNH4XoUTlNAhetRuB4lVEBmZmZmZsZUQLgehetRWFVAZGZmZmZGVkDfehSuR8FWQO5RuB6FS1dANjMzMzMTWEBzPQrXo7BYQGhmZmZmRllAEq5H4XrUWUDF9Shcj8JaQDsK16NwnVtAUrgehetRXED2KFyPwhVdQHgUrkfhul1ACNejcD2KXkB+FK5H4TpfQHsUrkfh+l9AFq5H4Xp0YEDhehSuR8FgQAvXo3A9CmFAZ2ZmZmZmYUDsUbgehathQClcj8L16GFAj8L1KFw/YkA=\",\"dtype\":\"float64\",\"shape\":[52]},\"total_intensity\":{\"__ndarray__\":\"AAAAAADWpUAAAAAAANSYQAAAAAAA6JRAAAAAAABclEAAAAAAAKiSQAAAAAAAwJJAAAAAAADUlkAAAAAAAJSaQAAAAAAAqJBAAAAAAAA4lEAAAAAAANCQQAAAAAAAgJBAAAAAAAAAkkAAAAAAAGCVQAAAAAAAhJRAAAAAAAB0lEAAAAAAAFSRQAAAAAAAMJJAAAAAAAAyjEAAAAAAAMiLQAAAAAAAZJBACtejcD2yikAAAAAAAFSbQAAAAAAAFqJAAAAAAADGokAAAAAAAJCjQAAAAAAAgqJAAAAAAADSoEAAAAAAAJqgQAAAAAAArqBAAAAAAAD0n0AAAAAAAPCeQAAAAAAAeqFAAAAAAADkn0AAAAAAALifQAAAAAAAQJ9AAAAAAABImkAAAAAAAMCbQAAAAAAAQJxAAAAAAACInEAAAAAAACyZQAAAAAAAkJpAAAAAAADQnkAAAAAAAFagQAAAAAAA8J9AAAAAAADWoEAAAAAAAP6hQAAAAAAA6qJAAAAAAABGpEAAAAAAAFSjQAAAAAAA3JhAAAAAAAAAmEA=\",\"dtype\":\"float64\",\"shape\":[52]}},\"selected\":{\"id\":\"1046\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1047\",\"type\":\"UnionRenderers\"}},\"id\":\"1034\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"ResetTool\"},{\"attributes\":{\"callback\":null},\"id\":\"1003\",\"type\":\"DataRange1d\"},{\"attributes\":{\"axis_label\":\"preactivation intensity\",\"formatter\":{\"id\":\"1044\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1017\",\"type\":\"BasicTicker\"}},\"id\":\"1016\",\"type\":\"LinearAxis\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1021\",\"type\":\"PanTool\"},{\"id\":\"1022\",\"type\":\"WheelZoomTool\"},{\"id\":\"1023\",\"type\":\"BoxZoomTool\"},{\"id\":\"1024\",\"type\":\"SaveTool\"},{\"id\":\"1025\",\"type\":\"ResetTool\"},{\"id\":\"1026\",\"type\":\"HelpTool\"}]},\"id\":\"1027\",\"type\":\"Toolbar\"},{\"attributes\":{\"text\":\"\"},\"id\":\"1041\",\"type\":\"Title\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"time_min\"},\"y\":{\"field\":\"preact_intensity\"}},\"id\":\"1037\",\"type\":\"Circle\"},{\"attributes\":{\"dimension\":1,\"ticker\":{\"id\":\"1017\",\"type\":\"BasicTicker\"}},\"id\":\"1020\",\"type\":\"Grid\"},{\"attributes\":{\"data_source\":{\"id\":\"1034\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1036\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1037\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"1039\",\"type\":\"CDSView\"}},\"id\":\"1038\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1017\",\"type\":\"BasicTicker\"},{\"attributes\":{\"source\":{\"id\":\"1034\",\"type\":\"ColumnDataSource\"}},\"id\":\"1039\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1012\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1042\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1026\",\"type\":\"HelpTool\"},{\"attributes\":{},\"id\":\"1044\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1007\",\"type\":\"LinearScale\"}],\"root_ids\":[\"1002\"]},\"title\":\"Bokeh Application\",\"version\":\"1.4.0\"}};\n",
       "  var render_items = [{\"docid\":\"dabe9b76-b988-4415-90af-6a5f9b319bf0\",\"roots\":{\"1002\":\"adf589ee-599a-46ac-b61d-4676b3d7b88e\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data. \n",
    "data = pd.read_csv('../processing/20200701_abrar_processed_munging/output/20200701_abrar_processed_data_tidy.csv')\n",
    "\n",
    "# Restrict to the first experiment. \n",
    "experiment = data[data['experiment_id']==1]\n",
    "\n",
    "# Set up a figure canvas. \n",
    "p = bokeh.plotting.figure(x_axis_label='time [min]', y_axis_label='preactivation intensity')\n",
    "# Plot the points\n",
    "p.circle(x='time_min', y='preact_intensity', source=experiment)\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_ab86d49a0d716b59eac073ab84e91b35 NOW.\n"
     ]
    }
   ],
   "source": [
    "model_code = \"\"\"\n",
    "\n",
    "functions {\n",
    "    // Function to generate posterior predictive samples\n",
    "    vector gp_ppc_rng(\n",
    "        real[] t_ppc,  // time points where to evaluate ppc\n",
    "        vector y,  // intensity measurements\n",
    "        real[] t_data,  // time points for intensities\n",
    "        real alpha,  // marginal standard deviation\n",
    "        real beta,  // time scale\n",
    "        real sigma,  // measurement error\n",
    "        real delta // extra value added for numerical stability\n",
    "    ) {\n",
    "    // Define variables for evaluation\n",
    "    int N_data = rows(y);  // number of data points\n",
    "    int N_ppc = size(t_ppc);  // number of time points on ppc\n",
    "    vector[N_ppc] f_ppc;  //  posterior predictive samples\n",
    "    {\n",
    "        // Objective: \n",
    "        // Generate covariance matrix for the data\n",
    "        matrix[N_data, N_data] K_exp = cov_exp_quad(t_data, alpha, beta);\n",
    "        matrix[N_data, N_data] K = K_exp \n",
    "        + diag_matrix(rep_vector(square(sigma), N_data));\n",
    "     \n",
    "        // 1. Perform Cholesky decomposition K = L_K L_K'\n",
    "        matrix[N_data, N_data] L_K = cholesky_decompose(K);\n",
    "    \n",
    "\n",
    "        // 2. Compute inv(L_K) y. Since L_K is a triangular matrix we can use\n",
    "        // the mdivide_left_tri_low function\n",
    "        vector[N_data] L_K_div_y_data = mdivide_left_tri_low(L_K, y);\n",
    "        // With this result in hand we can now solve for alpha by computing\n",
    "        // ⍺ = inv(L_k') inv(L_K) y. This is equivalent to ⍺ = inv(K) y\n",
    "\n",
    "        // 3. Compute ⍺ = inv(L_k') inv(L_K) y. Since L_K' is a triangular \n",
    "        // matrix we can use the mdivide_right_tri_low function\n",
    "        vector[N_data] K_div_y_data = mdivide_right_tri_low(\n",
    "            L_K_div_y_data', L_K\n",
    "        )';\n",
    "\n",
    "        // Generate covariance matrix for both data an ppc\n",
    "        matrix[N_data, N_ppc] k_t_data_t_ppc = cov_exp_quad(\n",
    "            t_data, t_ppc, alpha, beta\n",
    "        );\n",
    "        // Evaluate the mean function of the Gaussian process, given by\n",
    "  \n",
    "        vector[N_ppc] f_mu = (k_t_data_t_ppc' * K_div_y_data);\n",
    "\n",
    "        // Evaluate the variance function of the Gaussian process, given by\n",
    "      \n",
    "        // where K* is the covariance matrix of all the points to be evaluated.\n",
    "        // Using the fact that inv(K) = inv(L_K L_K') this can be rewritten as\n",
    "  \n",
    "        // 1. Evaluate inv(L_K) K*\n",
    "        matrix[N_data, N_ppc] v_pred = mdivide_left_tri_low(\n",
    "            L_K, k_t_data_t_ppc\n",
    "        );\n",
    "        // 2. Evaluate  = K* - K*' inv(L_K L_K') K*\n",
    "        matrix[N_ppc, N_ppc] cov_f_exp = cov_exp_quad(t_ppc, alpha, beta) ;\n",
    "        matrix[N_ppc, N_ppc] cov_f_exp2 = cov_f_exp - v_pred' * v_pred;\n",
    "        matrix[N_ppc, N_ppc] cov_f = cov_f_exp2 \n",
    "                                      + diag_matrix(rep_vector(delta, N_ppc));\n",
    "\n",
    "        // Generate random samples given the variance and covariance functions\n",
    "        // for the ppc samples\n",
    "        f_ppc = multi_normal_rng(f_mu, cov_f);\n",
    "    }\n",
    "    return f_ppc;\n",
    "    }\n",
    "}\n",
    "\n",
    "data {\n",
    "    // Data from intensity measurements\n",
    "    int<lower=1> N;  // number of data points\n",
    "    real t[N];  // time points where measurements were taken\n",
    "    vector[N] y;  // intensity\n",
    "\n",
    "    // Posterior Predictive Checks\n",
    "    int<lower=1> N_predict;  // number of points where to evalute ppc\n",
    "    real t_predict[N_predict];  // time points where to evaluate ppc\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    real<lower=0> beta;  // time scale\n",
    "    real<lower=0> alpha;  // marginal standard deviation\n",
    "    real<lower=0> sigma;  // measurement standard deviation\n",
    "}\n",
    "\n",
    "model {\n",
    "    // Define covariance matrix k(t, t')\n",
    "    matrix[N, N] cov_exp =  cov_exp_quad(t, alpha, beta);\n",
    "    matrix[N, N] cov = cov_exp + diag_matrix(rep_vector(square(sigma), N));\n",
    "    // Perform a Cholesky decomposition of the matrix, this means rewrite the\n",
    "    // covariance matrix cov = L_cov L_cov'\n",
    "    matrix[N, N] L_cov = cholesky_decompose(cov);\n",
    "    \n",
    "    // Sample data from a multinomial Gaussian with mean zero and rather than\n",
    "    // covariance matrix, a Cholesky decomposed matrix\n",
    "    y ~ multi_normal_cholesky(rep_vector(0, N), L_cov);\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "    // Generate posterior predictive samples for the Gaussian process\n",
    "    vector[N_predict] f_predict = gp_ppc_rng(\n",
    "        t_predict, y, t, alpha, beta, sigma, 1e-10\n",
    "    );\n",
    "    // Generate posterior predictive samples for the observation process\n",
    "    vector[N_predict] y_predict;\n",
    "    for (n in 1:N_predict) {\n",
    "        y_predict[n] = normal_rng(f_predict[n], sigma);\n",
    "    }\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "model = pystan.StanModel(model_code=model_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_predict = 500\n",
    "t_predict = np.linspace(0, 200, N_predict)\n",
    "t_predict_scaled = (t_predict - np.mean(t_predict)) / np.var(t_predict)\n",
    "preact_scaled = (experiment['preact_intensity'].values - np.mean(experiment['preact_intensity'].values)) / np.var(experiment['preact_intensity'].values)\n",
    "time_scaled = (experiment['time_min'].values - np.mean(experiment['time_min'].values)) / np.var(experiment['time_min'].values)  \n",
    "data_dict = {'t_predict':t_predict_scaled, 'N_predict':N_predict, 'y':preact_scaled, 't':time_scaled, 'N':len(experiment)}\n",
    "samples = model.sampling(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
